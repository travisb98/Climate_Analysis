{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set up engine and connection, not sure if connection is needed\n",
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")\n",
    "conn = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine,reflect=True)\n",
    "\n",
    "##### ---- not sure if I need this needed\n",
    "Base.metadata.create_all(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view all of the classes that automap found\n",
    "for x in Base.classes:\n",
    "    print(x)\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "mt = Base.classes.measurement\n",
    "st = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session=Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inspector=inspect(engine)\n",
    "\n",
    "# # ##--------------------------------------------\n",
    "m_columns=inspector.get_columns('measurement')\n",
    "\n",
    "s_columns=inspector.get_columns('station')\n",
    "\n",
    "print(\"measurement\")\n",
    "for m in m_columns:\n",
    "    print(m)\n",
    "    # print(m['name'],m['type'])\n",
    "print('-----')\n",
    "print(\"station\")\n",
    "for s in s_columns:\n",
    "    print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=engine.execute(\"SELECT * FROM measurement WHERE station in (SELECT station from station WHERE name like '%Honolulu%' )\").fetchall()\n",
    "# print(len(test))\n",
    "\n",
    "\n",
    "hon_sta_id=engine.execute(\"SELECT station from station WHERE name like '%Honolulu%'\").fetchall()[0][0]\n",
    "\n",
    "station=engine.execute(\"SELECT station,name FROM station\").fetchall()\n",
    "\n",
    "station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "\n",
    "####getting the max day from the measurement table and converting it into datetime format\n",
    "max_date = session.query(func.max(mt.date)).filter(mt.station==hon_sta_id).first()[0]\n",
    "max_date = dt.datetime.strptime(max_date,'%Y-%m-%d')\n",
    "\n",
    "# Calculate the date 1 year ago from the last data point in the database\n",
    "year_ago =(max_date - dt.timedelta(weeks=52)).replace(day=max_date.day)\n",
    "\n",
    "##### converting it into a format that we're able to query with\n",
    "year_ago = f'{year_ago.year}-{year_ago.month:02d}-{year_ago.day:02d}'\n",
    "\n",
    "\n",
    "\n",
    "# Perform a query to retrieve the data and precipitation scores\n",
    "annual_pre_list = session.query(mt.date,mt.prcp).filter(mt.station==hon_sta_id,mt.date>year_ago).all()\n",
    "\n",
    "\n",
    "year_list =[pd.to_datetime(x,format='%Y-%m-%d') for x,y in annual_pre_list]\n",
    "precip_list = [y for x,y in annual_pre_list]\n",
    "# print(type(year_list[0]))\n",
    "\n",
    "# Save the query results as a Pandas DataFrame and set the index to the date column &  Sort the dataframe by date, and remove null values\n",
    "annual_pre_df = pd.DataFrame({\"precipitation\":precip_list},index=year_list).sort_index().dropna()\n",
    "# # Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "#### defining x ticks as every 30 days\n",
    "x_ticks=[annual_pre_df.index[0]]\n",
    "for x in range(12):\n",
    "    new_date = x_ticks[-1] + dt.timedelta(days=30)\n",
    "    x_ticks.append(new_date)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(annual_pre_df.index,annual_pre_df.precipitation,width=3)\n",
    "plt.xticks(x_ticks,rotation='vertical')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Inches of Rain\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "annual_pre_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "station_count = engine.execute(\"SELECT COUNT(station.id) FROM station\").fetchall()[0][0]\n",
    "print(f'There are {station_count} stations in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature of the most active station?\n",
    "\n",
    "\n",
    "station_activity_list = engine.execute(\"SELECT DISTINCT station, (SELECT COUNT(measurement.id) FROM measurement WHERE measurement.station=station.station) as meas_count,(SELECT MAX(measurement.tobs) FROM measurement WHERE measurement.station=station.station) as max_temp,(SELECT MIN(measurement.tobs)FROM measurement WHERE measurement.station=station.station) as min_temp,ROUND((SELECT AVG(measurement.tobs)FROM measurement WHERE measurement.station=station.station),2) as avg_temp, name FROM station ORDER BY meas_count DESC\").fetchall()\n",
    "\n",
    "\n",
    "station_summary_df=pd.DataFrame(station_activity_list,columns=['station','measurement_count','max_temp','min_temp','avg_temp','name'])\n",
    "\n",
    "\n",
    "\n",
    "# List the stations and the counts in descending order.\n",
    "print(f'There are {station_count} stations in the dataset. {station_summary_df[\"name\"][0]} is the most active station with {station_summary_df[\"measurement_count\"][0]} measurements recorded')\n",
    "station_summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "top_station=station_summary_df[\"station\"][0]\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n",
    "\n",
    "### find the first and last date we'll be plotting\n",
    "#######do i need to change this to filter for the top station id????\n",
    "top_last_date = dt.datetime.strptime(session.query(mt.date,mt.tobs).order_by(mt.date.desc()).first()[0],'%Y-%m-%d')\n",
    "top_first_date = top_last_date - dt.timedelta(days=365)\n",
    "\n",
    "\n",
    "##### using the first and last date for the top station, query the temp data\n",
    "\n",
    "top_station_temps_df=pd.DataFrame(session.query(mt.date,mt.tobs).filter(mt.station==top_station,mt.date>top_first_date).all())\n",
    "###making the date he index\n",
    "top_station_temps_df.set_index('date',inplace=True)\n",
    "\n",
    "\n",
    "print(len(top_station_temps_df))\n",
    "top_station_temps_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "bin=np.arange(55,85,2)\n",
    "bin\n",
    "print(len(top_station_temps_df))\n",
    "fig,ax=plt.subplots(figsize=(8,6))\n",
    "ax.hist(top_station_temps.tobs,bins=bin)\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### store the variables needed for the api file called app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# # and return the minimum, average, and maximum temperatures for that range of dates\n",
    "# def calc_temps(start_date, end_date):\n",
    "#     \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "#     Args:\n",
    "#         start_date (string): A date string in the format %Y-%m-%d\n",
    "#         end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "#     Returns:\n",
    "#         TMIN, TAVE, and TMAX\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "#         filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# # function usage example\n",
    "# print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a query that will calculate the daily normals \n",
    "# # (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "# def daily_normals(date):\n",
    "#     \"\"\"Daily Normals.\n",
    "    \n",
    "#     Args:\n",
    "#         date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "#     Returns:\n",
    "#         A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "#     return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "# daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7e7c916c673641125590bd307b68bb4342787996dc085909d7e5c72ee4d13010"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}